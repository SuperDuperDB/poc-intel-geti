{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89fc820f-7b6c-4add-8b2d-e70069a6d0db",
   "metadata": {},
   "source": [
    "# INTEL GETI Docs Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3885e6a8-6118-4e0f-9875-f35470421479",
   "metadata": {},
   "source": [
    "## Crawling Pages\n",
    "\n",
    "Crawl pages based on the provided links. Additionally, retrieve a list of new pages from the sidebar directory information and continue crawling until all pages have been crawled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffcb8b87-3750-4998-a305-825fdd57c6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhouhaha/workspace/SuperDuperDB/poc-intel-geti/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-03-06 22:43:37,030\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m 2024-Mar-06 22:43:37.03\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mzhouhaha-2.local\u001b[0m| \u001b[36msuperduperdb.base.build\u001b[0m:\u001b[36m65  \u001b[0m | \u001b[1mData Client is ready. mongomock.MongoClient('localhost', 27017)\u001b[0m\n",
      "\u001b[32m 2024-Mar-06 22:43:37.04\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mzhouhaha-2.local\u001b[0m| \u001b[36msuperduperdb.base.build\u001b[0m:\u001b[36m38  \u001b[0m | \u001b[1mConnecting to Metadata Client with engine:  mongomock.MongoClient('localhost', 27017)\u001b[0m\n",
      "\u001b[32m 2024-Mar-06 22:43:37.04\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mzhouhaha-2.local\u001b[0m| \u001b[36msuperduperdb.base.build\u001b[0m:\u001b[36m148 \u001b[0m | \u001b[1mConnecting to compute client: local\u001b[0m\n",
      "\u001b[32m 2024-Mar-06 22:43:37.04\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mzhouhaha-2.local\u001b[0m| \u001b[36msuperduperdb.base.datalayer\u001b[0m:\u001b[36m85  \u001b[0m | \u001b[1mBuilding Data Layer\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from superduperdb import superduper\n",
    "import os\n",
    "mongodb_uri = os.getenv(\"SUPERDUPERDB_DATA_BACKEND\",\"mongomock://test\")\n",
    "db = superduper(mongodb_uri)\n",
    "db.drop(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6964c15-4c01-4d20-a6d4-5d6469983f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def process_code_snippets(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    pre_tags = soup.find_all(\"pre\")\n",
    "\n",
    "    for pre in pre_tags:\n",
    "        processed_text = str(pre.text)\n",
    "        new_content = \"CODE::\" + soup.new_string(processed_text)\n",
    "        pre.clear()\n",
    "        pre.append(new_content)\n",
    "    return str(soup)\n",
    "\n",
    "\n",
    "def process_py_class(source_html):\n",
    "    soup = BeautifulSoup(source_html, \"html.parser\")\n",
    "    dl_tags = soup.find_all(\"dl\", class_=\"py class\")\n",
    "\n",
    "    for dl in dl_tags:\n",
    "        dt_tag = dl.find(\"dt\", class_=\"sig sig-object py\")\n",
    "        if not dt_tag:\n",
    "            continue\n",
    "        last_headerlink = dt_tag.find_all(\"a\", class_=\"headerlink\")[-1]\n",
    "        href = last_headerlink[\"href\"] if last_headerlink else \"\"\n",
    "        id = dt_tag.attrs[\"id\"]\n",
    "        new_h3 = soup.new_tag(\"h3\")\n",
    "        new_a_inside_h3 = soup.new_tag(\"a\", href=href)\n",
    "        new_a_inside_h3.string = f\"Class: {id}\"\n",
    "        new_h3.append(new_a_inside_h3)\n",
    "\n",
    "        new_code = soup.new_tag(\"a\")\n",
    "        new_code.string = dt_tag.text\n",
    "        dt_tag.insert_before(new_h3)\n",
    "        dt_tag.insert_before(new_code)\n",
    "        dt_tag.decompose()\n",
    "\n",
    "    return str(soup)\n",
    "\n",
    "\n",
    "def parse_url(seed_url):\n",
    "    print(f\"parse {seed_url}\")\n",
    "    response = requests.get(seed_url)\n",
    "    # Parse the HTML content\n",
    "    source_html = response.text\n",
    "    source_html = process_code_snippets(source_html)\n",
    "    source_html = process_py_class(source_html)\n",
    "\n",
    "    return source_html\n",
    "\n",
    "\n",
    "def url2html(url):\n",
    "    return parse_url(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3c8688-9d57-410e-8232-7232257e0417",
   "metadata": {},
   "source": [
    "## Importing Webpage Data into Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ae0143-8ae2-4efe-b46e-f8b165e4be6e",
   "metadata": {},
   "source": [
    "### Using SuperduperDB to Connect to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bedba21d-f2da-4da5-8a73-d091a8130dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhouhaha/workspace/SuperDuperDB/poc-intel-geti/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-03-04 21:49:47,055\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m 2024-Mar-04 21:49:47.06\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36msuperduperdb.base.build\u001b[0m:\u001b[36m65  \u001b[0m | \u001b[1mData Client is ready. MongoClient(host=['127.0.0.1:27017'], document_class=dict, tz_aware=False, connect=True, serverselectiontimeoutms=5000)\u001b[0m\n",
      "\u001b[32m 2024-Mar-04 21:49:47.07\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36msuperduperdb.base.build\u001b[0m:\u001b[36m38  \u001b[0m | \u001b[1mConnecting to Metadata Client with engine:  MongoClient(host=['127.0.0.1:27017'], document_class=dict, tz_aware=False, connect=True, serverselectiontimeoutms=5000)\u001b[0m\n",
      "\u001b[32m 2024-Mar-04 21:49:47.08\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36msuperduperdb.base.build\u001b[0m:\u001b[36m148 \u001b[0m | \u001b[1mConnecting to compute client: local\u001b[0m\n",
      "\u001b[32m 2024-Mar-04 21:49:47.08\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36msuperduperdb.base.datalayer\u001b[0m:\u001b[36m85  \u001b[0m | \u001b[1mBuilding Data Layer\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from superduperdb import superduper\n",
    "db = superduper(\"mongodb://127.0.0.1:27017/intel-geti\")\n",
    "db.drop(force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51be29fe-8558-426e-98e2-68045cb4a6fe",
   "metadata": {},
   "source": [
    "Store the webpage data into the database after unstructured parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8c4fb8e-86ea-4bc7-b68c-f5d289a00d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m 2024-Mar-04 21:49:49.18\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36msuperduperdb.components.component\u001b[0m:\u001b[36m333 \u001b[0m | \u001b[1mInitializing DataType : dill\u001b[0m\n",
      "\u001b[32m 2024-Mar-04 21:49:49.18\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36msuperduperdb.components.component\u001b[0m:\u001b[36m336 \u001b[0m | \u001b[1mInitialized  DataType : dill successfully\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 21:49:50] unstructured INFO Reading document from string ...\n",
      "[2024-03-04 21:49:50] unstructured INFO Reading document ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m 2024-Mar-04 21:49:50.83\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36msuperduperdb.components.component\u001b[0m:\u001b[36m333 \u001b[0m | \u001b[1mInitializing DataType : unstructured\u001b[0m\n",
      "\u001b[32m 2024-Mar-04 21:49:50.83\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36msuperduperdb.components.component\u001b[0m:\u001b[36m336 \u001b[0m | \u001b[1mInitialized  DataType : unstructured successfully\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ObjectId('65e5d17ea0a7ed69fcf48cd7')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unstructured.partition.html import partition_html\n",
    "from superduperdb.ext.unstructured.encoder import unstructured_encoder\n",
    "\n",
    "db.add(unstructured_encoder)\n",
    "\n",
    "datas = []\n",
    "for url, source_html in pages:\n",
    "    elements = partition_html(text=source_html, html_assemble_articles=True)\n",
    "    if elements:\n",
    "        datas.append({'url': url, 'elements': unstructured_encoder(elements)})\n",
    "\n",
    "from superduperdb import Document\n",
    "from superduperdb.backends.mongodb import Collection\n",
    "documents = list(map(Document, datas))\n",
    "collection = Collection(\"pages\")\n",
    "collection.insert_many(documents).execute(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5556877a-3b7e-4f7e-a675-c4b6c82309ad",
   "metadata": {},
   "source": [
    "## Parsing and Chunking Webpages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b0fb34-909d-4a99-903b-06602073a3bc",
   "metadata": {},
   "source": [
    "Define an title ecognition function to be used as chunk identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d37b889-91e0-4394-bc5a-2573564cd91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.documents.elements import ElementType\n",
    "\n",
    "def get_title_data(element):\n",
    "    data = {}\n",
    "    if element.category != ElementType.TITLE:\n",
    "        return data\n",
    "    if 'link_urls' not in element.metadata.to_dict():\n",
    "        return data\n",
    "\n",
    "    if 'category_depth' not in element.metadata.to_dict():\n",
    "        return data\n",
    "\n",
    "    [link_text, *_] = element.metadata.link_texts\n",
    "\n",
    "    if not link_text:\n",
    "        return data\n",
    "\n",
    "    link_urls = element.metadata.link_urls\n",
    "    if not link_urls:\n",
    "        return data\n",
    "    category_depth = element.metadata.category_depth\n",
    "    return {'link': link_urls[0], 'category_depth':category_depth}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62b2c13-caa8-4810-a75d-e36fe2028064",
   "metadata": {},
   "source": [
    "Define conversion methods for different types of text, such as titles, lists, tables, and code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec51fd27-2ef1-48df-add3-83d07b98c2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "def element2text(element):\n",
    "    title_message = get_title_data(element)\n",
    "    text = element.text\n",
    "    if title_message:\n",
    "        title_tags = '#' * (title_message['category_depth'] + 1)\n",
    "        text = title_tags + ' ' + text\n",
    "        text = text.rstrip('#')\n",
    "\n",
    "    elif element.category == ElementType.LIST_ITEM:\n",
    "        text = '- ' + text\n",
    "\n",
    "    elif element.category == ElementType.TABLE:\n",
    "        html = element.metadata.text_as_html\n",
    "        html = html.replace('|', '')\n",
    "        df = pd.read_html(StringIO(html))[0]\n",
    "        text = df.to_markdown(index=False)\n",
    "        text = text + '  \\n'\n",
    "\n",
    "    if text.startswith(\"CODE::\"):\n",
    "        text = f\"```\\n{text[6:]}\\n```\"\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef35cb56-520e-40be-bdd1-f6ee4240f490",
   "metadata": {},
   "source": [
    "Define chunking functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63b09f64-edeb-4b71-8ce1-c13f24ccbec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunk_texts(text, chunk_size=1000, overlap_size=300):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "\n",
    "    while start < len(text):\n",
    "        if chunks:\n",
    "            start -= overlap_size\n",
    "        end = start + chunk_size\n",
    "        end = min(end, len(text))\n",
    "        chunks.append(text[start:end])\n",
    "        start = end\n",
    "        if start >= len(text):\n",
    "            break\n",
    "\n",
    "    return chunks\n",
    "\n",
    "from collections import defaultdict\n",
    "def get_chunks(elements):\n",
    "    chunk_tree = defaultdict(list)\n",
    "    now_depth = -1\n",
    "    now_path = 'root'\n",
    "    for element in elements:\n",
    "        title_data = get_title_data(element)\n",
    "        if not title_data:\n",
    "            chunk_tree[now_path].append(element)\n",
    "        else:\n",
    "            link = title_data['link']\n",
    "            depth = title_data['category_depth']\n",
    "            if depth > now_depth:\n",
    "                now_path = now_path + \"::\" +link\n",
    "            else:\n",
    "                now_path = '::'.join(now_path.split(\"::\")[:depth+1] + [link])\n",
    "            now_depth = depth\n",
    "            chunk_tree[now_path].append(element)\n",
    "     \n",
    "    chunks = []\n",
    "    for node_path, node_elements in chunk_tree.items():\n",
    "        new_elements = []\n",
    "        nodes = node_path.split(\"::\")\n",
    "        parent_elements = []\n",
    "        for i in range(1, len(nodes) - 1):\n",
    "            [parent_element, *_] = chunk_tree[\"::\".join(nodes[:i+1])] or [None]\n",
    "            if parent_element:\n",
    "                parent_elements.append(parent_element)\n",
    "        node_elements = [*parent_elements, *node_elements]\n",
    "        content = '\\n\\n'.join(map(lambda x: element2text(x), node_elements))\n",
    "        for chunk_text in get_chunk_texts(content):\n",
    "            # The url field is used to save the jump link\n",
    "            # The text field is used for vector search\n",
    "            # The content field is used to submit to LLM for answer\n",
    "            chunk = {\"url\": nodes[-1], 'text': chunk_text, 'content': content}\n",
    "            chunks.append(chunk_text)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ffc9e0-6148-4886-bd5d-b2ed43364364",
   "metadata": {},
   "source": [
    "Define a chunking model and add a Listener to listen to data and chunk webpages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "606472b7-cda9-454e-9c9d-8ee5f122bade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m 2024-Mar-04 21:49:51.04\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36msuperduperdb.components.component\u001b[0m:\u001b[36m333 \u001b[0m | \u001b[1mInitializing DataType : dill\u001b[0m\n",
      "\u001b[32m 2024-Mar-04 21:49:51.04\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36msuperduperdb.components.component\u001b[0m:\u001b[36m336 \u001b[0m | \u001b[1mInitialized  DataType : dill successfully\u001b[0m\n",
      "\u001b[32m 2024-Mar-04 21:49:51.09\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36msuperduperdb.backends.local.compute\u001b[0m:\u001b[36m32  \u001b[0m | \u001b[1mSubmitting job. function:<function method_job at 0x12f494430>\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 689.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m 2024-Mar-04 21:49:51.10\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36msuperduperdb.components.component\u001b[0m:\u001b[36m333 \u001b[0m | \u001b[1mInitializing ObjectModel : chunk\u001b[0m\n",
      "\u001b[32m 2024-Mar-04 21:49:51.10\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36msuperduperdb.components.component\u001b[0m:\u001b[36m336 \u001b[0m | \u001b[1mInitialized  ObjectModel : chunk successfully\u001b[0m\n",
      "\u001b[32m 2024-Mar-04 21:49:51.10\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36msuperduperdb.components.model\u001b[0m:\u001b[36m649 \u001b[0m | \u001b[1mAdding 1 model outputs to `db`\u001b[0m\n",
      "\u001b[32m 2024-Mar-04 21:49:51.12\u001b[0m| \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36msuperduperdb.backends.local.compute\u001b[0m:\u001b[36m38  \u001b[0m | \u001b[32m\u001b[1mJob submitted.  function:<function method_job at 0x12f494430> future:0c2da506-8f0a-44f0-9f2a-d544cab83345\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<superduperdb.jobs.job.ComponentJob at 0x291b115d0>],\n",
       " Listener(identifier='chunk/elements', key='elements', model=ObjectModel(identifier='chunk', signature='*args,**kwargs', datatype=None, output_schema=Schema(identifier='myschema', fields={'text': 'string'}), flatten=True, model_update_kwargs={'document_embedded': False}, metrics=(), validation_sets=None, predict_kwargs={}, object=<function get_chunks at 0x28e1b5b40>, num_workers=0), select=<superduperdb.backends.mongodb.query.MongoCompoundSelect[\n",
       "     \u001b[92m\u001b[1mpages.find({}, {})\u001b[0m\n",
       " ] object at 0x291b13850>, active=True, predict_kwargs={}))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from superduperdb import Model, Listener, Schema\n",
    "\n",
    "\n",
    "chunk_model = Model(\n",
    "    identifier='chunk',\n",
    "    object=get_chunks,\n",
    "    flatten=True,\n",
    "    model_update_kwargs={\"document_embedded\": False},\n",
    "    output_schema=Schema(identifier=\"myschema\", fields={\"text\": \"string\"}),\n",
    ")\n",
    "\n",
    "db.add(\n",
    "    Listener(\n",
    "        model=chunk_model,\n",
    "        select=Collection('pages').find(),\n",
    "        key=\"elements\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe6130a-03e3-4788-9be9-014386ad7fb1",
   "metadata": {},
   "source": [
    "## Building Vector Search Feature Using OpenAIEmbedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "122cb103-30de-414e-b36f-b2a85fbcd1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 21:53:16] httpx INFO HTTP Request: GET https://api.openai.com/v1/models \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m 2024-Mar-04 21:53:16.83\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36msuperduperdb.backends.local.compute\u001b[0m:\u001b[36m32  \u001b[0m | \u001b[1mSubmitting job. function:<function method_job at 0x12f494430>\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00, 2459.28it/s]\n",
      "  0%|                                                                           | 0/1 [00:00<?, ?it/s][2024-03-04 21:53:17] httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "100%|███████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m 2024-Mar-04 21:53:18.05\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36msuperduperdb.components.model\u001b[0m:\u001b[36m649 \u001b[0m | \u001b[1mAdding 6 model outputs to `db`\u001b[0m\n",
      "\u001b[32m 2024-Mar-04 21:53:18.08\u001b[0m| \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36msuperduperdb.backends.local.compute\u001b[0m:\u001b[36m38  \u001b[0m | \u001b[32m\u001b[1mJob submitted.  function:<function method_job at 0x12f494430> future:6352ce50-2098-460e-a965-51216908a4c8\u001b[0m\n",
      "\u001b[32m 2024-Mar-04 21:53:18.09\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36msuperduperdb.backends.local.compute\u001b[0m:\u001b[36m32  \u001b[0m | \u001b[1mSubmitting job. function:<function callable_job at 0x12f494700>\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'_outputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/workspace/SuperDuperDB/superduperdb/superduperdb/misc/special_dicts.py:32\u001b[0m, in \u001b[0;36mMongoStyleDict.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: '_outputs._outputs.elements.chunk.text-embedding-ada-002.2'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/workspace/SuperDuperDB/superduperdb/superduperdb/misc/special_dicts.py:32\u001b[0m, in \u001b[0;36mMongoStyleDict.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: '_outputs.elements.chunk.text-embedding-ada-002.2'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 25\u001b[0m\n\u001b[1;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m OpenAIEmbedding(\n\u001b[1;32m     16\u001b[0m     identifier\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext-embedding-ada-002\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     17\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-ada-002\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# preprocess = Model(\"preprocess\", object=preprocess)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# from superduperdb.components.model import SequentialModel\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# emb_model = SequentialModel(identifier=\"emb\", predictors=[preprocess, model])\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mVectorIndex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43midentifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvector_index\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindexing_listener\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mListener\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[43mselect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCollection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_outputs.elements.chunk\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_outputs.elements.chunk\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Key for the documents\u001b[39;49;00m\n\u001b[1;32m     31\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Specify the model for processing\u001b[39;49;00m\n\u001b[1;32m     32\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredict_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_chunk_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/SuperDuperDB/superduperdb/superduperdb/base/datalayer.py:484\u001b[0m, in \u001b[0;36mDatalayer.add\u001b[0;34m(self, object, dependencies)\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mobject\u001b[39m)(\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add(\n\u001b[1;32m    478\u001b[0m             \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m=\u001b[39mcomponent,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m component \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\n\u001b[1;32m    482\u001b[0m     )\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mobject\u001b[39m, Component):\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdependencies\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mobject\u001b[39m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add(superduper(\u001b[38;5;28mobject\u001b[39m)), \u001b[38;5;28mobject\u001b[39m\n",
      "File \u001b[0;32m~/workspace/SuperDuperDB/superduperdb/superduperdb/base/datalayer.py:843\u001b[0m, in \u001b[0;36mDatalayer._add\u001b[0;34m(self, object, dependencies, serialized, parent)\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39mpost_create(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_component_to_cache(\u001b[38;5;28mobject\u001b[39m)\n\u001b[0;32m--> 843\u001b[0m these_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule_jobs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdependencies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m jobs\u001b[38;5;241m.\u001b[39mextend(these_jobs)\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jobs\n",
      "File \u001b[0;32m~/workspace/SuperDuperDB/superduperdb/superduperdb/components/vector_index.py:198\u001b[0m, in \u001b[0;36mVectorIndex.schedule_jobs\u001b[0;34m(self, db, dependencies)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03mSchedule jobs for the listener\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m:param verbose: Whether to print verbose output\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m job \u001b[38;5;241m=\u001b[39m FunctionJob(\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28mcallable\u001b[39m\u001b[38;5;241m=\u001b[39mcopy_vectors,\n\u001b[1;32m    191\u001b[0m     args\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m     },\n\u001b[1;32m    197\u001b[0m )\n\u001b[0;32m--> 198\u001b[0m \u001b[43mjob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdependencies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [job]\n",
      "File \u001b[0;32m~/workspace/SuperDuperDB/superduperdb/superduperdb/jobs/job.py:140\u001b[0m, in \u001b[0;36mFunctionJob.__call__\u001b[0;34m(self, db, dependencies)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb \u001b[38;5;241m=\u001b[39m db\n\u001b[1;32m    138\u001b[0m db\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mcreate_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdict())\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdependencies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/workspace/SuperDuperDB/superduperdb/superduperdb/jobs/job.py:117\u001b[0m, in \u001b[0;36mFunctionJob.submit\u001b[0;34m(self, dependencies)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msubmit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dependencies\u001b[38;5;241m=\u001b[39m()):\n\u001b[1;32m    112\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    Submit job for execution\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m    :param dependencies: list of dependencies\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallable_job\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunction_to_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midentifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdependencies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/SuperDuperDB/superduperdb/superduperdb/backends/local/compute.py:33\u001b[0m, in \u001b[0;36mLocalComputeBackend.submit\u001b[0;34m(self, function, *args, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03mSubmits a function for local execution.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m:param function: The function to be executed.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSubmitting job. function:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m future \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m future_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4())\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__outputs[future_key] \u001b[38;5;241m=\u001b[39m future\n",
      "File \u001b[0;32m~/workspace/SuperDuperDB/superduperdb/superduperdb/jobs/tasks.py:120\u001b[0m, in \u001b[0;36mcallable_job\u001b[0;34m(cfg, function_to_call, args, kwargs, job_id, dependencies, local, db)\u001b[0m\n\u001b[1;32m    118\u001b[0m     db\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mupdate_job(job_id, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    119\u001b[0m     db\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mupdate_job(job_id, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmsg\u001b[39m\u001b[38;5;124m'\u001b[39m, tb)\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     db\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mupdate_job(job_id, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/workspace/SuperDuperDB/superduperdb/superduperdb/jobs/tasks.py:107\u001b[0m, in \u001b[0;36mcallable_job\u001b[0;34m(cfg, function_to_call, args, kwargs, job_id, dependencies, local, db)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m local:\n\u001b[0;32m--> 107\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43mfunction_to_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m         output \u001b[38;5;241m=\u001b[39m handle_function_output(\n\u001b[1;32m    110\u001b[0m             function_to_call,\n\u001b[1;32m    111\u001b[0m             db\u001b[38;5;241m=\u001b[39mdb,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m             kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m    115\u001b[0m         )\n",
      "File \u001b[0;32m~/workspace/SuperDuperDB/superduperdb/superduperdb/vector_search/update_tasks.py:60\u001b[0m, in \u001b[0;36mcopy_vectors\u001b[0;34m(vector_index, query, ids, db)\u001b[0m\n\u001b[1;32m     58\u001b[0m vectors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(db\u001b[38;5;241m.\u001b[39mdatabackend, MongoDataBackend):\n\u001b[0;32m---> 60\u001b[0m     vectors \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     61\u001b[0m         {\n\u001b[1;32m     62\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvector\u001b[39m\u001b[38;5;124m'\u001b[39m: MongoStyleDict(doc)[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_outputs.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     63\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mstr\u001b[39m(doc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_id\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     64\u001b[0m         }\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs\n\u001b[1;32m     66\u001b[0m     ]\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(db\u001b[38;5;241m.\u001b[39mdatabackend, IbisDataBackend):\n\u001b[1;32m     68\u001b[0m     docs \u001b[38;5;241m=\u001b[39m db\u001b[38;5;241m.\u001b[39mexecute(select\u001b[38;5;241m.\u001b[39moutputs(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{key: model}))\n",
      "File \u001b[0;32m~/workspace/SuperDuperDB/superduperdb/superduperdb/vector_search/update_tasks.py:62\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     58\u001b[0m vectors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(db\u001b[38;5;241m.\u001b[39mdatabackend, MongoDataBackend):\n\u001b[1;32m     60\u001b[0m     vectors \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     61\u001b[0m         {\n\u001b[0;32m---> 62\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvector\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mMongoStyleDict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_outputs.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkey\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mversion\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[1;32m     63\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mstr\u001b[39m(doc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_id\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     64\u001b[0m         }\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs\n\u001b[1;32m     66\u001b[0m     ]\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(db\u001b[38;5;241m.\u001b[39mdatabackend, IbisDataBackend):\n\u001b[1;32m     68\u001b[0m     docs \u001b[38;5;241m=\u001b[39m db\u001b[38;5;241m.\u001b[39mexecute(select\u001b[38;5;241m.\u001b[39moutputs(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{key: model}))\n",
      "File \u001b[0;32m~/workspace/SuperDuperDB/superduperdb/superduperdb/misc/special_dicts.py:38\u001b[0m, in \u001b[0;36mMongoStyleDict.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     36\u001b[0m child \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(parts[\u001b[38;5;241m1\u001b[39m:])\n\u001b[1;32m     37\u001b[0m sub \u001b[38;5;241m=\u001b[39m MongoStyleDict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(parent))\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msub\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/workspace/SuperDuperDB/superduperdb/superduperdb/misc/special_dicts.py:37\u001b[0m, in \u001b[0;36mMongoStyleDict.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     35\u001b[0m parent \u001b[38;5;241m=\u001b[39m parts[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     36\u001b[0m child \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(parts[\u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m---> 37\u001b[0m sub \u001b[38;5;241m=\u001b[39m MongoStyleDict(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sub[child]\n",
      "File \u001b[0;32m~/workspace/SuperDuperDB/superduperdb/superduperdb/misc/special_dicts.py:29\u001b[0m, in \u001b[0;36mMongoStyleDict.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m key:\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: '_outputs'"
     ]
    }
   ],
   "source": [
    "from superduperdb.ext.openai import OpenAIEmbedding\n",
    "from tqdm import tqdm\n",
    "\n",
    "from superduperdb.ext.openai import OpenAIEmbedding\n",
    "from superduperdb import VectorIndex\n",
    "\n",
    "def preprocess(x):\n",
    "    if isinstance(x, dict):\n",
    "        # For model chains, the logic of this key needs to be optimized.\n",
    "        chunk = sorted(x.items())[-1][1]\n",
    "        return chunk[\"text\"]\n",
    "    return x\n",
    "\n",
    "# Create an instance of the OpenAIEmbedding model with the specified identifier ('text-embedding-ada-002')\n",
    "model = OpenAIEmbedding(\n",
    "    identifier='text-embedding-ada-002',\n",
    "    model=\"text-embedding-ada-002\",\n",
    ")\n",
    "# preprocess = Model(\"preprocess\", object=preprocess)\n",
    "\n",
    "# from superduperdb.components.model import SequentialModel\n",
    "# emb_model = SequentialModel(identifier=\"emb\", predictors=[preprocess, model])\n",
    "\n",
    "\n",
    "db.add(\n",
    "    VectorIndex(\n",
    "        identifier='vector_index',\n",
    "        indexing_listener=Listener(\n",
    "            select=Collection('_outputs.elements.chunk').find(),\n",
    "            key='_outputs.elements.chunk',  # Key for the documents\n",
    "            model=model,  # Specify the model for processing\n",
    "            predict_kwargs={\"max_chunk_size\": 64},\n",
    "        ),\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4477b3-eab2-48b5-bbe9-e223c80646dc",
   "metadata": {},
   "source": [
    "Define a function for vector search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0250b6aa-4fcc-464d-87e8-e6a911810a11",
   "metadata": {},
   "source": [
    "# Create vector search and Chatbot applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f1b885-ff42-45dc-be2e-649ab2b674dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = superduper(\"mongodb://127.0.0.1:27017/intel-geti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c92c51-f81d-4b70-93fc-281b0849f600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(db, query, top_k=5):\n",
    "    logging.info(f\"Vector search query: {query}\")\n",
    "    collection = Collection('_outputs.elements.chunk')\n",
    "    outs = db.execute(\n",
    "        collection.like(\n",
    "            Document({\"_outputs.elements.chunk\": query}),\n",
    "            vector_index=\"vector_index\",\n",
    "            n=top_k,\n",
    "        ).find({})\n",
    "    )\n",
    "    if outs:\n",
    "        outs = sorted(outs, key=lambda x: x.content[\"score\"], reverse=True)\n",
    "    for out in outs:\n",
    "        print(\"-\" * 20, '\\n')\n",
    "        data = out.outputs(\"elements\", 'chunk')\n",
    "    \n",
    "        source = out.content['_source']\n",
    "        source_url = Collection('pages').find_one({\"_id\": source}).execute(db)['url']\n",
    "        data = out.outputs(\"elements\", 'chunk')\n",
    "        url = source_url + data['url']\n",
    "        print(url, out['score'])\n",
    "        print(data[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372fb2c1-1de1-482e-baee-1553b4f72c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_search(db, \"What parameters does the DeployedModel class have?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f553ec94-83e9-4d48-aeb4-10f9ef329f94",
   "metadata": {},
   "source": [
    "## Building Document Functionality Using ChatGPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4651daa0-8fc0-43b9-935b-ffcec51e0204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduperdb.ext.openai import OpenAIChatCompletion\n",
    "prompt = \"\"\"\n",
    "As an Intel GETI assistant, based on the provided documents and the question, answer the question.\n",
    "If the document does not provide an answer, offer a safe response without fabricating an answer.\n",
    "\n",
    "Documents:\n",
    "{context}\n",
    "\n",
    "Question: \"\"\"\n",
    "\n",
    "llm = OpenAIChatCompletion(identifier='gpt-3.5-turbo', prompt=prompt)\n",
    "\n",
    "db.add(llm)\n",
    "\n",
    "print(db.show('model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9010e120-c948-4ebd-8969-8d1614b8afb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa(db, query, vector_search_top_k=5):\n",
    "    logging.info(f\"QA query: {query}\")\n",
    "    collection = Collection(\"_outputs.elements.chunk\")\n",
    "    output, sources = db.predict(\n",
    "        model_name='gpt-3.5-turbo',\n",
    "        input=query,\n",
    "        context_select=collection.like(\n",
    "            Document({\"_outputs.elements.chunk\": query}),\n",
    "            vector_index=\"vector_index\",\n",
    "            n=vector_search_top_k,\n",
    "        ).find({}),\n",
    "        context_key=\"_outputs.elements.chunk.0.content\",\n",
    "    )\n",
    "    if sources:\n",
    "        sources = sorted(sources, key=lambda x: x.content[\"score\"], reverse=True)\n",
    "    return output, sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3389ba-0cea-4e77-ba93-79532ee8baa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "output, sources = qa(db, \"What parameters does the DeployedModel class have?\")\n",
    "display(Markdown(output.content))\n",
    "for source in sources:\n",
    "    source_data = source.content['_source']\n",
    "    source_url = Collection('pages').find_one({\"_id\": source_data}).execute(db)['url']\n",
    "    data = source.outputs(\"elements\", 'chunk')\n",
    "    url = source_url + data['url']\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e17c5e-f200-404e-9c4a-993d8990abad",
   "metadata": {},
   "outputs": [],
   "source": [
    "source.outputs(\"elements\", 'chunk')[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e866c224-cc9c-4283-8cee-a3c2c28a3b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
