{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89fc820f-7b6c-4add-8b2d-e70069a6d0db",
   "metadata": {},
   "source": [
    "# INTEL GETI Docs Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3923a0-d10f-44b7-9c8a-8cc499953173",
   "metadata": {},
   "source": [
    "Install related dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8580979-8994-41a1-818a-24bef3cec47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install superduperdb unstructured pandas openai aiohttp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3885e6a8-6118-4e0f-9875-f35470421479",
   "metadata": {},
   "source": [
    "## Crawling Pages\n",
    "\n",
    "Crawl pages based on the provided links. Additionally, retrieve a list of new pages from the sidebar directory information and continue crawling until all pages have been crawled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6964c15-4c01-4d20-a6d4-5d6469983f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse https://openvinotoolkit.github.io/geti-sdk/index.html\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def is_toctree_class(tag):\n",
    "    classes = tag.get('class', [])\n",
    "    return any(re.match('toctree-l\\d+', cls) for cls in classes)\n",
    "\n",
    "def filter_sub_urls(all_urls):\n",
    "    # remove the URL with #, for example: http://xxxx.com/xxx#P1\n",
    "    base_urls_set = {url for _, url in all_urls if '#' not in url}\n",
    "    new_urls = []\n",
    "    for page_name, url in all_urls:\n",
    "        if '#' in url and url.split('#')[0] in base_urls_set:\n",
    "            continue\n",
    "        else:\n",
    "            new_urls.append((page_name, url))\n",
    "    return new_urls\n",
    "\n",
    "def process_code_snippets(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    pre_tags = soup.find_all('pre')\n",
    "\n",
    "    for pre in pre_tags:\n",
    "        processed_text = str(pre.text)\n",
    "        new_content = \"CODE::\"+soup.new_string(processed_text)\n",
    "        pre.clear()\n",
    "        pre.append(new_content)\n",
    "    return str(soup)\n",
    "            \n",
    "    \n",
    "def parse_url(seed_url):\n",
    "    print(f\"parse {seed_url}\")\n",
    "    response = requests.get(seed_url)\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    page_urls = []\n",
    "    for l in soup.find_all(is_toctree_class):\n",
    "        page_name = l.find('a').text.strip()\n",
    "        href = l.find('a')['href'] if l.find('a') else ''\n",
    "        if href:\n",
    "            url = urljoin(seed_url, href)\n",
    "            page_urls.append((page_name, url))\n",
    "\n",
    "    page_urls = filter_sub_urls(page_urls)\n",
    "    source_html = response.text\n",
    "    source_html = process_code_snippets(source_html)\n",
    "            \n",
    "    return source_html, page_urls\n",
    "\n",
    "# URL of the page to scrape\n",
    "filter_tag = \"geti_sdk.\"\n",
    "url_sets = set()\n",
    "url_sets.add(\"https://openvinotoolkit.github.io/geti-sdk/index.html\")\n",
    "url_sets.add(\"https://docs.geti.intel.com/on-prem/1.8/guide/get-started/introduction.html\")\n",
    "url_waiting_list = url_sets.copy()\n",
    "pages = list()\n",
    "while url_waiting_list:\n",
    "    url = url_waiting_list.pop()\n",
    "    source_html, page_urls = parse_url(url)\n",
    "    pages.append((url, source_html))\n",
    "    new_urls = {url for _, url in page_urls if url not in url_sets}\n",
    "    new_urls = {url for url in new_urls if filter_tag not in url}\n",
    "    url_waiting_list.update(new_urls)\n",
    "    url_sets.update(new_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3c8688-9d57-410e-8232-7232257e0417",
   "metadata": {},
   "source": [
    "## Importing Webpage Data into Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ae0143-8ae2-4efe-b46e-f8b165e4be6e",
   "metadata": {},
   "source": [
    "### Using SuperduperDB to Connect to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bedba21d-f2da-4da5-8a73-d091a8130dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhouhaha/workspace/SuperDuperDB/poc-geti/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-02-19 19:59:53,006\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m 2024-Feb-19 19:59:53.01\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36m1cd33afc-bd71-4b70-bdcf-eac97e6bf5b6\u001b[0m| \u001b[36msuperduperdb.base.build\u001b[0m:\u001b[36m61  \u001b[0m | \u001b[1mData Client is ready. MongoClient(host=['127.0.0.1:27017'], document_class=dict, tz_aware=False, connect=True, serverselectiontimeoutms=5000)\u001b[0m\n",
      "\u001b[32m 2024-Feb-19 19:59:53.02\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36m1cd33afc-bd71-4b70-bdcf-eac97e6bf5b6\u001b[0m| \u001b[36msuperduperdb.base.build\u001b[0m:\u001b[36m36  \u001b[0m | \u001b[1mConnecting to Metadata Client with engine:  MongoClient(host=['127.0.0.1:27017'], document_class=dict, tz_aware=False, connect=True, serverselectiontimeoutms=5000)\u001b[0m\n",
      "\u001b[32m 2024-Feb-19 19:59:53.02\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36m1cd33afc-bd71-4b70-bdcf-eac97e6bf5b6\u001b[0m| \u001b[36msuperduperdb.base.build\u001b[0m:\u001b[36m144 \u001b[0m | \u001b[1mConnecting to compute client: local\u001b[0m\n",
      "\u001b[32m 2024-Feb-19 19:59:53.02\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36m1cd33afc-bd71-4b70-bdcf-eac97e6bf5b6\u001b[0m| \u001b[36msuperduperdb.base.datalayer\u001b[0m:\u001b[36m80  \u001b[0m | \u001b[1mBuilding Data Layer\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from superduperdb import superduper\n",
    "db = superduper(\"mongodb://127.0.0.1:27017/intel-geti\")\n",
    "db.drop(force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51be29fe-8558-426e-98e2-68045cb4a6fe",
   "metadata": {},
   "source": [
    "Store the webpage data into the database after unstructured parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8c4fb8e-86ea-4bc7-b68c-f5d289a00d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-19 19:59:58] unstructured INFO Reading document from string ...\n",
      "[2024-02-19 19:59:58] unstructured INFO Reading document ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ObjectId('65d342bf09daef992f82d532')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unstructured.partition.html import partition_html\n",
    "from superduperdb.ext.unstructured.encoder import unstructured_encoder\n",
    "\n",
    "db.add(unstructured_encoder)\n",
    "\n",
    "datas = []\n",
    "for url, source_html in pages:\n",
    "    elements = partition_html(text=source_html, html_assemble_articles=True)\n",
    "    if elements:\n",
    "        datas.append({'url': url, 'elements': unstructured_encoder(elements)})\n",
    "\n",
    "from superduperdb import Document\n",
    "from superduperdb.backends.mongodb import Collection\n",
    "documents = list(map(Document, datas))\n",
    "collection = Collection(\"pages\")\n",
    "collection.insert_many(documents).execute(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5556877a-3b7e-4f7e-a675-c4b6c82309ad",
   "metadata": {},
   "source": [
    "## Parsing and Chunking Webpages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b0fb34-909d-4a99-903b-06602073a3bc",
   "metadata": {},
   "source": [
    "Define an title ecognition function to be used as chunk identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d37b889-91e0-4394-bc5a-2573564cd91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.documents.elements import ElementType\n",
    "\n",
    "def get_title_data(element):\n",
    "    data = {}\n",
    "    if element.category != ElementType.TITLE:\n",
    "        return data\n",
    "    if 'link_urls' not in element.metadata.to_dict():\n",
    "        return data\n",
    "\n",
    "    if 'category_depth' not in element.metadata.to_dict():\n",
    "        return data\n",
    "\n",
    "    [link_text, *_] = element.metadata.link_texts\n",
    "\n",
    "    if not link_text:\n",
    "        return data\n",
    "\n",
    "    link_urls = element.metadata.link_urls\n",
    "    if not link_urls:\n",
    "        return data\n",
    "    category_depth = element.metadata.category_depth\n",
    "    return {'link': link_urls[0], 'category_depth':category_depth}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62b2c13-caa8-4810-a75d-e36fe2028064",
   "metadata": {},
   "source": [
    "Define conversion methods for different types of text, such as titles, lists, tables, and code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec51fd27-2ef1-48df-add3-83d07b98c2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "def element2text(element):\n",
    "    title_message = get_title_data(element)\n",
    "    text = element.text\n",
    "    if title_message:\n",
    "        title_tags = '#' * (title_message['category_depth'] + 1)\n",
    "        text = title_tags + ' ' + text\n",
    "        text = text.rstrip('#')\n",
    "\n",
    "    elif element.category == ElementType.LIST_ITEM:\n",
    "        text = '- ' + text\n",
    "\n",
    "    elif element.category == ElementType.TABLE:\n",
    "        html = element.metadata.text_as_html\n",
    "        html = html.replace('|', '')\n",
    "        df = pd.read_html(StringIO(html))[0]\n",
    "        text = df.to_markdown(index=False)\n",
    "        text = text + '  \\n'\n",
    "\n",
    "    if text.startswith(\"CODE::\"):\n",
    "        text = f\"```\\n{text[6:]}\\n```\"\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef35cb56-520e-40be-bdd1-f6ee4240f490",
   "metadata": {},
   "source": [
    "Define chunking functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63b09f64-edeb-4b71-8ce1-c13f24ccbec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def get_chunks(elements):\n",
    "    chunk_tree = defaultdict(list)\n",
    "    now_depth = -1\n",
    "    now_path = 'root'\n",
    "    for element in elements:\n",
    "        title_data = get_title_data(element)\n",
    "        if not title_data:\n",
    "            chunk_tree[now_path].append(element)\n",
    "        else:\n",
    "            link = title_data['link']\n",
    "            depth = title_data['category_depth']\n",
    "            if depth > now_depth:\n",
    "                now_path = now_path + \"::\" +link\n",
    "            else:\n",
    "                now_path = '::'.join(now_path.split(\"::\")[:depth+1] + [link])\n",
    "            now_depth = depth\n",
    "            chunk_tree[now_path].append(element)\n",
    "     \n",
    "    chunks = []\n",
    "    for node_path, node_elements in chunk_tree.items():\n",
    "        new_elements = []\n",
    "        nodes = node_path.split(\"::\")\n",
    "        parent_elements = []\n",
    "        for i in range(1, len(nodes) - 1):\n",
    "            [parent_element, *_] = chunk_tree[\"::\".join(nodes[:i+1])] or [None]\n",
    "            if parent_element:\n",
    "                parent_elements.append(parent_element)\n",
    "        node_elements = [*parent_elements, *node_elements]\n",
    "        chunk = {\"url\": nodes[-1], 'text': '\\n\\n'.join(map(lambda x: element2text(x), node_elements))}\n",
    "        chunks.append(chunk)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ffc9e0-6148-4886-bd5d-b2ed43364364",
   "metadata": {},
   "source": [
    "Define a chunking model and add a Listener to listen to data and chunk webpages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "606472b7-cda9-454e-9c9d-8ee5f122bade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 680.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m 2024-Feb-19 20:00:12.40\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36m1cd33afc-bd71-4b70-bdcf-eac97e6bf5b6\u001b[0m| \u001b[36msuperduperdb.components.model\u001b[0m:\u001b[36m477 \u001b[0m | \u001b[1mAdding 1 model outputs to `db`\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([None],\n",
       " Listener(identifier='chunk/elements', key='elements', model=Model(identifier='chunk', encoder=None, output_schema=Schema(identifier='myschema', fields={'text': 'string', '_fold': FieldType(identifier='String')}), flatten=True, preprocess=None, postprocess=None, collate_fn=None, batch_predict=False, takes_context=False, metrics=(), model_update_kwargs={'document_embedded': False}, validation_sets=None, predict_X=None, predict_select=None, predict_max_chunk_size=None, predict_kwargs=None, object=<Artifact artifact=<function get_chunks at 0x102edf760> serializer=dill>, model_to_device_method=None, metric_values={}, predict_method=None, serializer='dill', device='cpu', preferred_devices=('cuda', 'mps', 'cpu'), training_configuration=None, train_X=None, train_y=None, train_select=None), select=<superduperdb.backends.mongodb.query.MongoCompoundSelect[\n",
       "     \u001b[92m\u001b[1mpages.find({'_id': \"{'$in': '[65d342bf09daef992f82d532]'}\"}, {})\u001b[0m\n",
       " ] object at 0x28141afe0>, active=True, predict_kwargs={}))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from superduperdb import Model, Listener, Schema\n",
    "\n",
    "\n",
    "chunk_model = Model(\n",
    "    identifier='chunk',\n",
    "    object=get_chunks,\n",
    "    flatten=True,\n",
    "    model_update_kwargs={\"document_embedded\": False},\n",
    "    output_schema=Schema(identifier=\"myschema\", fields={\"text\": \"string\"}),\n",
    ")\n",
    "\n",
    "db.add(\n",
    "    Listener(\n",
    "        model=chunk_model,\n",
    "        select=Collection('pages').find(),\n",
    "        key=\"elements\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe6130a-03e3-4788-9be9-014386ad7fb1",
   "metadata": {},
   "source": [
    "## Building Vector Search Feature Using OpenAIEmbedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "122cb103-30de-414e-b36f-b2a85fbcd1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-19 20:00:34] httpx INFO HTTP Request: GET https://api.openai.com/v1/models \"HTTP/1.1 200 OK\"\n",
      "2it [00:00, 1320.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m 2024-Feb-19 20:00:34.98\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36m1cd33afc-bd71-4b70-bdcf-eac97e6bf5b6\u001b[0m| \u001b[36msuperduperdb.components.model\u001b[0m:\u001b[36m417 \u001b[0m | \u001b[1mComputing chunk 0/0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                        | 0/1 [00:00<?, ?it/s][2024-02-19 20:00:35] httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m 2024-Feb-19 20:00:36.10\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36m1cd33afc-bd71-4b70-bdcf-eac97e6bf5b6\u001b[0m| \u001b[36msuperduperdb.components.model\u001b[0m:\u001b[36m477 \u001b[0m | \u001b[1mAdding 2 model outputs to `db`\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([None],\n",
       " VectorIndex(identifier='vector_index', indexing_listener=Listener(identifier='text-embedding-ada-002/elements', key='_outputs.elements.chunk', model=OpenAIEmbedding(encoder=Encoder(identifier='vector[1536]', decoder=None, encoder=None, shape=(1536,), load_hybrid=True), output_schema=None, flatten=False, preprocess=<Artifact artifact=<function preprocess at 0x28321f010> serializer=dill>, postprocess=None, collate_fn=None, batch_predict=False, takes_context=False, metrics=(), model_update_kwargs={}, validation_sets=None, predict_X=None, predict_select=None, predict_max_chunk_size=None, predict_kwargs=None, identifier='text-embedding-ada-002', model='text-embedding-ada-002', client_kwargs={}, shape=(1536,)), select=<superduperdb.backends.mongodb.query.MongoCompoundSelect[\n",
       "     \u001b[92m\u001b[1m_outputs.elements.chunk.elements.chunk.find({'_id': \"{'$in': '[65d342cc09daef992f82d539, 65d342cc09daef992f82d53a]'}\"}, {})\u001b[0m\n",
       " ] object at 0x283298ac0>, active=True, predict_kwargs={'max_chunk_size': 64}), compatible_listener=None, measure=<VectorIndexMeasureType.cosine: 'cosine'>, metric_values={}))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from superduperdb.ext.openai import OpenAIEmbedding\n",
    "from superduperdb.base.artifact import Artifact\n",
    "from tqdm import tqdm\n",
    "def _predict(self, X, one: bool = False, **kwargs):\n",
    "    if isinstance(X, str) or one:\n",
    "        if isinstance(self.preprocess, Artifact):\n",
    "            X = self.preprocess.artifact(X)\n",
    "        return self._predict_one(X)\n",
    "\n",
    "    if isinstance(self.preprocess, Artifact):\n",
    "        X = [self.preprocess.artifact(i) for i in X]\n",
    "\n",
    "    out = []\n",
    "    batch_size = kwargs.pop(\"batch_size\", 100)\n",
    "    for i in tqdm(range(0, len(X), batch_size)):\n",
    "        out.extend(self._predict_a_batch(X[i : i + batch_size], **kwargs))\n",
    "    return out\n",
    "\n",
    "\n",
    "OpenAIEmbedding._predict = _predict\n",
    "\n",
    "from superduperdb.ext.openai import OpenAIEmbedding\n",
    "from superduperdb.base.artifact import Artifact\n",
    "from superduperdb import VectorIndex\n",
    "\n",
    "def preprocess(x):\n",
    "    if isinstance(x, dict):\n",
    "        # For model chains, the logic of this key needs to be optimized.\n",
    "        chunk = sorted(x.items())[-1][1]\n",
    "        return chunk[\"text\"]\n",
    "    return x\n",
    "\n",
    "# Create an instance of the OpenAIEmbedding model with the specified identifier ('text-embedding-ada-002')\n",
    "model = OpenAIEmbedding(\n",
    "    identifier='text-embedding-ada-002',\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    preprocess=Artifact(preprocess),\n",
    ")\n",
    "\n",
    "\n",
    "db.add(\n",
    "    VectorIndex(\n",
    "        identifier='vector_index',\n",
    "        indexing_listener=Listener(\n",
    "            select=Collection('_outputs.elements.chunk').find(),\n",
    "            key='_outputs.elements.chunk',  # Key for the documents\n",
    "            model=model,  # Specify the model for processing\n",
    "            predict_kwargs={\"max_chunk_size\": 64},\n",
    "        ),\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4477b3-eab2-48b5-bbe9-e223c80646dc",
   "metadata": {},
   "source": [
    "Define a function for vector search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "227fa3d2-ffff-489a-a549-76aff63fb65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(db, query, top_k=5):\n",
    "    logging.info(f\"Vector search query: {query}\")\n",
    "    collection = Collection('_outputs.elements.chunk')\n",
    "    outs = db.execute(\n",
    "        collection.like(\n",
    "            Document({\"_outputs.elements.chunk\": query}),\n",
    "            vector_index=\"vector_index\",\n",
    "            n=top_k,\n",
    "        ).find({})\n",
    "    )\n",
    "    if outs:\n",
    "        outs = sorted(outs, key=lambda x: x.content[\"score\"], reverse=True)\n",
    "    for out in outs:\n",
    "        print(\"-\" * 20, '\\n')\n",
    "        data = out.outputs(\"elements\", 'chunk')\n",
    "    \n",
    "        source = out.content['_source']\n",
    "        source_url = Collection('pages').find_one({\"_id\": source}).execute(db)['url']\n",
    "        data = out.outputs(\"elements\", 'chunk')\n",
    "        url = source_url + data['url']\n",
    "        print(url, out['score'])\n",
    "        print(data[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07f1b885-ff42-45dc-be2e-649ab2b674dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = superduper(\"mongodb://127.0.0.1:27017/intel-geti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "372fb2c1-1de1-482e-baee-1553b4f72c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-19 20:00:39] root INFO Vector search query: Learn how to interact with the Intel® Geti™ platform programmatically, bypassing the user interface.\n",
      "[2024-02-19 20:00:39] httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m 2024-Feb-19 20:00:39.79\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36m1cd33afc-bd71-4b70-bdcf-eac97e6bf5b6\u001b[0m| \u001b[36msuperduperdb.base.datalayer\u001b[0m:\u001b[36m154 \u001b[0m | \u001b[1mloading of vectors of vector-index: 'vector_index'\u001b[0m\n",
      "\u001b[32m 2024-Feb-19 20:00:39.79\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36m1cd33afc-bd71-4b70-bdcf-eac97e6bf5b6\u001b[0m| \u001b[36msuperduperdb.base.datalayer\u001b[0m:\u001b[36m170 \u001b[0m | \u001b[1m<superduperdb.backends.mongodb.query.MongoCompoundSelect[\n",
      "    \u001b[92m\u001b[1m_outputs.elements.chunk.elements.chunk.find({'_id': \"{'$in': '[65d342cc09daef992f82d539, 65d342cc09daef992f82d53a]'}\"}, {'_outputs.elements.text-embedding-ada-002.0': '1', '_outputs.elements.text-embedding-ada-002/0': '1', '_id': '1'})\u001b[0m\n",
      "] object at 0x28141bee0>\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading vectors into vector-table...: 2it [00:00, 253.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- \n",
      "\n",
      "https://openvinotoolkit.github.io/geti-sdk/index.html#intel-geti-sdk-documentation 0.8250750622783525\n",
      "# Intel® Geti™ SDK documentation\n",
      "\n",
      "Welcome to the documentation for the Intel® Geti™ SDK! The purpose of this SDK is twofold:\n",
      "\n",
      "- Provide an easy-to-use interface to the Intel® Geti™ platform, to manipulate\n",
      "Intel® Geti™ projects and other entities or automate tasks on the platform. All\n",
      "of this from a Python script or Jupyter notebook.\n",
      "\n",
      "- Provide an API to deploy and run models trained on the Intel® Geti™ server on your local\n",
      "machine. The SDK deployment module provides a straightforward\n",
      "route to create a deployment for your Intel® Geti™ project, save it to a local disk and run\n",
      "it offline.\n",
      "\n",
      "This SDK includes various example scripts and Jupyter notebooks which illustrate a\n",
      "range of use cases for the SDK. Make sure to check them out if you’re getting\n",
      "started!\n",
      "\n",
      "Contents:\n",
      "\n",
      "- Introduction\n",
      "\n",
      "- Getting started\n",
      "\n",
      "- Supported features\n",
      "\n",
      "- Notebooks\n",
      "\n",
      "- Contributing to the SDK\n",
      "\n",
      "- API Reference\n",
      "-------------------- \n",
      "\n",
      "https://openvinotoolkit.github.io/geti-sdk/index.html#indices-and-tables 0.7088565972920741\n",
      "# Indices and tables\n",
      "\n",
      "- Index\n",
      "\n",
      "- Module Index\n",
      "\n",
      "- Search Page\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outs = vector_search(db, \"Learn how to interact with the Intel® Geti™ platform programmatically, bypassing the user interface.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f553ec94-83e9-4d48-aeb4-10f9ef329f94",
   "metadata": {},
   "source": [
    "## Building Document Functionality Using ChatGPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4651daa0-8fc0-43b9-935b-ffcec51e0204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chunk', 'gpt-3.5-turbo', 'text-embedding-ada-002']\n"
     ]
    }
   ],
   "source": [
    "from superduperdb.ext.openai import OpenAIChatCompletion\n",
    "prompt = \"\"\"\n",
    "As an Intel GETI assistant, based on the provided document snippets and the question, answer the question.\n",
    "If the document does not provide an answer, offer a safe response without fabricating an answer.\n",
    "\n",
    "Document snippet: {context}\n",
    "\n",
    "Question: \"\"\"\n",
    "\n",
    "llm = OpenAIChatCompletion(identifier='gpt-3.5-turbo', prompt=prompt)\n",
    "\n",
    "db.add(llm)\n",
    "\n",
    "print(db.show('model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9010e120-c948-4ebd-8969-8d1614b8afb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa(db, query, vector_search_top_k=5):\n",
    "    logging.info(f\"QA query: {query}\")\n",
    "    collection = Collection(\"_outputs.elements.chunk\")\n",
    "    output, sources = db.predict(\n",
    "        model_name='gpt-3.5-turbo',\n",
    "        input=query,\n",
    "        context_select=collection.like(\n",
    "            Document({\"_outputs.elements.chunk\": query}),\n",
    "            vector_index=\"vector_index\",\n",
    "            n=vector_search_top_k,\n",
    "        ).find({}),\n",
    "        context_key=\"_outputs.elements.chunk.0.text\",\n",
    "    )\n",
    "    if sources:\n",
    "        sources = sorted(sources, key=lambda x: x.content[\"score\"], reverse=True)\n",
    "    return output, sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d3389ba-0cea-4e77-ba93-79532ee8baa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-19 20:00:57] root INFO QA query: How to install\n",
      "[2024-02-19 20:00:58] httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "[2024-02-19 20:01:00] httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "To install the Intel® Geti™ SDK, you can follow the steps outlined in the \"Getting started\" section of the documentation. This typically includes downloading the SDK package from the official Intel website, running the installation script, and setting up any necessary dependencies. If you encounter any issues during the installation process, you can refer to the documentation for troubleshooting tips or reach out to Intel support for assistance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://openvinotoolkit.github.io/geti-sdk/index.html#indices-and-tables\n",
      "https://openvinotoolkit.github.io/geti-sdk/index.html#intel-geti-sdk-documentation\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "output, sources = qa(db, \"How to install\")\n",
    "display(Markdown(output.content))\n",
    "for source in sources:\n",
    "    source_data = source.content['_source']\n",
    "    source_url = Collection('pages').find_one({\"_id\": source_data}).execute(db)['url']\n",
    "    data = source.outputs(\"elements\", 'chunk')\n",
    "    url = source_url + data['url']\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e17c5e-f200-404e-9c4a-993d8990abad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
